---
title: "Data"
---

# 1. General Information About Data

The Turkish Statistical Institute (TÃœÄ°K) is motivated to ensure the production, publication and distribution of necessary statistics while compiling Turkey's education data and information. TÃœÄ°K collects data from individuals, households, workplaces through surveys and censuses. The education data it collects helps to compare education information and gives an idea of â€‹â€‹what education needs a country has for its development.

**Data Source:** [TÃœÄ°K](https://data.tuik.gov.tr/Bulten/Index?p=Ulusal-Egitim-Istatistikleri-2023-53444)

# 2. Why We Choose Data and Our Purposes

As part of the EMU430 course, we decided to examine the National Education Statistics dataset published by the Turkish Statistical Institute (TÃœÄ°K). This dataset provides comprehensive information about the state of education in Turkey. It is particularly suitable for analyzing issues such as reading rates, gender differences in education, and regional education levels.

Education plays a key role in the development of a society. Therefore, by choosing this dataset for our project, we aim to determine the strengths of Turkey's education system and areas that need improvement. We plan to make important inferences about education with this data.

The main goal of our project is to conduct an in-depth analysis of the state and trends of education in Turkey. In this context, we will seek answers to the following questions:

Are there differences in education levels between genders? Has education equality been achieved regionally? How has the level of education in Turkey progressed over the years?

By answering these questions, we aim to understand the problems in the education system and develop suggestions that can contribute to education policies in Turkey.

# 3. Data Preprocessing and EDA Analysis


---
title: "Data Preprocessing Report"
author: "Education Atlas    "
date: today
format: 
  html:
    toc: true
    toc-depth: 2
    code-fold: true
    code-summary: "Code Details"
execute:
  echo: true
  warning: false
  error: true
---

# ğŸ“Š Introduction

This project aims to analyze **educational data from 2008 to 2023**. The following preprocessing steps prepare the dataset for analysis:

1. Data loading and removal of empty columns  
2. Partitioning data by years  
3. Column header adjustment  
4. Creating multi-level column headers  

---

# ğŸ› ï¸ Step 0: Manual Data Preprocessing in Excel
Before starting data analysis, the dataset was manually cleaned in Excel to ensure consistency and accuracy:

1. Empty Columns Removed: Completely empty columns were deleted.
2. City Name Standardization: Inconsistent city names (e.g., Afyonkarahisar â†’ Afyon, Ä°Ã§el â†’ Mersin) were corrected.
3. Unnecessary Rows Cleared: Rows containing summary totals (e.g., labeled as TÃ¼rkiye) and metadata were removed.
4. Header Adjustments: Column headers were standardized, and missing values were filled.

This cleaned dataset (yÄ±llara_gÃ¶re_egitim.xlsx) was then used for further processing in Python. ğŸš€





# âš™ï¸ Step 1: Data Loading and Cleaning

The dataset is loaded using Python's `pandas` library, and completely empty columns are removed.

```python
import pandas as pd

# Load the dataset and remove completely empty columns
df = pd.read_excel('data/yÄ±llara_gÃ¶re_egitim.xlsx')
df = df.dropna(axis=1, how='all')
```

**Description:**  
- The dataset is loaded using the `pandas` library.  
- Completely empty columns are removed from the dataset.

---

# ğŸ“… Step 2: Partitioning Data by Years

The dataset is partitioned into separate data frames for each year.

```python
# Define years and index ranges
years = list(range(2008, 2024))  # From 2008 to 2023
index_ranges = [(1 + i * 82, 1 + (i + 1) * 82) for i in range(len(years))]

# Create sub-data frames for each year
yearly_data = {}
for year, (start, end) in zip(years, index_ranges):
    yearly_data[year] = df.iloc[start:end]
```

**Description:**  
- The dataset is partitioned into yearly data frames.  
- Index ranges are calculated for each year.

---

# ğŸ” Step 3: Viewing Sample Years

Sample records from the first three years are examined.

```python
# Inspect sample data frames from the first few years
sample_years = {year: data.head(1) for year, data in list(yearly_data.items())[:3]}

# Display sample data for verification
for year, sample in sample_years.items():
    print(f"Sample data for year {year}:")
    print(sample)
```

**Description:**  
- Data frames for the first three years are inspected.  
- Header structure is validated.  
- Sample data from the first row of each year's data frame is displayed.

---

# ğŸ“ Step 4: Adjusting Column Headers

The first two rows are used as column headers, and missing values are filled.

```python
import pandas as pd
df = pd.read_excel('data/yÄ±llara_gÃ¶re_egitim.xlsx')
df = df.dropna(axis=1, how='all')
years = list(range(2008, 2024))  # From 2008 to 2023
index_ranges = [(1 + i * 82, 1 + (i + 1) * 82) for i in range(len(years))]

# Create sub-data frames for each year
yearly_data = {}
for year, (start, end) in zip(years, index_ranges):
    yearly_data[year] = df.iloc[start:end]
# Use the first two rows as headers and fill missing values
header1 = df.iloc[0].bfill()
header2 = df.iloc[1].bfill()

# Create multi-level (MultiIndex) headers
df.columns = pd.MultiIndex.from_tuples(zip(header1, header2))

# Remove the first two rows and reset the dataset
df = df.iloc[2:].reset_index(drop=True)
```

**Description:**  
- The first two rows are used as column headers.  
- Missing values are filled (`bfill`).  
- Multi-level headers are created.

---

# ğŸ“‘ Step 5: Structuring Column Headers

Column headers are further structured.

```{python}
import pandas as pd
df = pd.read_excel('data/yÄ±llara_gÃ¶re_egitim.xlsx')
df = df.dropna(axis=1, how='all')
years = list(range(2008, 2024))  # From 2008 to 2023
index_ranges = [(1 + i * 82, 1 + (i + 1) * 82) for i in range(len(years))]

# Create sub-data frames for each year
yearly_data = {}
for year, (start, end) in zip(years, index_ranges):
    yearly_data[year] = df.iloc[start:end]
# Use the first two rows as headers and fill missing values
header1 = df.iloc[0].bfill()
header2 = df.iloc[1].bfill()

# Create multi-level (MultiIndex) headers
df.columns = pd.MultiIndex.from_tuples(zip(header1, header2))

# Remove the first two rows and reset the dataset
df = df.iloc[2:].reset_index(drop=True)
# Create single-level headers for the first three columns
first_three_headers = ['Year', 'Province Code', 'Province Name']

# Define main and sub-headers
main_headers = [
    'Genel toplam', 'Okuma yazma bilmeyen', 'Okuma yazma bilen fakat bir okul bitirmeyen',
    'Ä°lkokul', 'Ä°lkÃ¶ÄŸretim', 'Ortaokul ve dengi meslek', 'Lise ve dengi meslek',
    'YÃ¼ksekokul veya fakÃ¼lte', 'YÃ¼ksek lisans', 'Doktora', 'Bilinmeyen'
]
sub_headers = ['Toplam', 'Erkek', 'KadÄ±n']

# Create multi-level headers
remaining_headers = [(main, sub) for main in main_headers for sub in sub_headers]

# Combine all headers
final_headers = first_three_headers + remaining_headers[:df.shape[1] - len(first_three_headers)]

df.columns = pd.MultiIndex.from_tuples(
    [(header, '') if isinstance(header, str) else header for header in final_headers]
)
```

**Description:**  
- Single-level headers are assigned to the first three columns.  
- Multi-level headers are created for remaining columns.  
- Final column structure is established.

---

# ğŸ“Š Step 6: Data Structure Verification

```python
# Display dataset information
print(df.info())

# Display the first few rows of the dataset
print(df.head())
```

```{python}
import pandas as pd

# Veri setini yÃ¼kle ve tamamen boÅŸ sÃ¼tunlarÄ± kaldÄ±r
df = pd.read_excel('/home/mami/emu430/emu430-fall2024-team-education_atlas/data/yÄ±llara_gÃ¶re_egitim.xlsx')
df = df.dropna(axis=1, how='all')

# YÄ±llarÄ± ve indeks aralÄ±klarÄ±nÄ± tanÄ±mla
years = list(range(2008, 2024))  # 2008'den 2023'e kadar
index_ranges = [(1 + i * 82, 1 + (i + 1) * 82) for i in range(len(years))]

# Her yÄ±l iÃ§in alt veri Ã§erÃ§evelerini oluÅŸtur
yearly_data = {}
for year, (start, end) in zip(years, index_ranges):
    yearly_data[year] = df.iloc[start:end]

# Ä°lk birkaÃ§ yÄ±lÄ±n veri Ã§erÃ§evelerini kontrol et
sample_years = {year: data.head(1) for year, data in list(yearly_data.items())[:3]}

# Ä°lk iki satÄ±rÄ± baÅŸlÄ±k olarak kullan ve eksik deÄŸerleri doldur
header1 = df.iloc[0].bfill()
header2 = df.iloc[1].bfill()

# Ã‡ok seviyeli (MultiIndex) baÅŸlÄ±klar oluÅŸtur
df.columns = pd.MultiIndex.from_tuples(zip(header1, header2))

# Ä°lk iki satÄ±rÄ± kaldÄ±r ve veri setini sÄ±fÄ±rla
df = df.iloc[2:].reset_index(drop=True)

# Ä°lk 3 sÃ¼tun iÃ§in tek seviyeli baÅŸlÄ±klar oluÅŸtur
first_three_headers = ['YÄ±l', 'Ä°l Kodu', 'Ä°l AdÄ±']

# Ana baÅŸlÄ±klar ve alt baÅŸlÄ±klarÄ± tanÄ±mla
main_headers = [
    'Genel toplam', 'Okuma yazma bilmeyen', 'Okuma yazma bilen fakat bir okul bitirmeyen',
    'Ä°lkokul', 'Ä°lkÃ¶ÄŸretim', 'Ortaokul ve dengi meslek', 'Lise ve dengi meslek',
    'YÃ¼ksekokul veya fakÃ¼lte', 'YÃ¼ksek lisans', 'Doktora', 'Bilinmeyen'
]
sub_headers = ['Toplam', 'Erkek', 'KadÄ±n']

# Ã‡ok seviyeli baÅŸlÄ±klarÄ± oluÅŸtur
remaining_headers = [(main, sub) for main in main_headers for sub in sub_headers]

# TÃ¼m baÅŸlÄ±klarÄ± birleÅŸtir
final_headers = first_three_headers + remaining_headers[:df.shape[1] - len(first_three_headers)]

df.columns = pd.MultiIndex.from_tuples(
    [(header, '') if isinstance(header, str) else header for header in final_headers]
)

print(df.loc[df['YÄ±l'] == 2009])

```

# ğŸš€ R'de .RData formatÄ±nda kaydetmek iÃ§in aÅŸaÄŸÄ±daki komutlarÄ± kullanabilirsiniz:

```{python}
import pandas as pd

# Veri setini yÃ¼kle ve tamamen boÅŸ sÃ¼tunlarÄ± kaldÄ±r
df = pd.read_excel('/home/mami/emu430/emu430-fall2024-team-education_atlas/data/yÄ±llara_gÃ¶re_egitim.xlsx')
df = df.dropna(axis=1, how='all')

# YÄ±llarÄ± ve indeks aralÄ±klarÄ±nÄ± tanÄ±mla
years = list(range(2008, 2024))  # 2008'den 2023'e kadar
index_ranges = [(1 + i * 82, 1 + (i + 1) * 82) for i in range(len(years))]

# Her yÄ±l iÃ§in alt veri Ã§erÃ§evelerini oluÅŸtur
yearly_data = {}
for year, (start, end) in zip(years, index_ranges):
    yearly_data[year] = df.iloc[start:end]

# Ä°lk birkaÃ§ yÄ±lÄ±n veri Ã§erÃ§evelerini kontrol et
sample_years = {year: data.head(1) for year, data in list(yearly_data.items())[:3]}

# Ä°lk iki satÄ±rÄ± baÅŸlÄ±k olarak kullan ve eksik deÄŸerleri doldur
header1 = df.iloc[0].bfill()
header2 = df.iloc[1].bfill()

# Ã‡ok seviyeli (MultiIndex) baÅŸlÄ±klar oluÅŸtur
df.columns = pd.MultiIndex.from_tuples(zip(header1, header2))

# Ä°lk iki satÄ±rÄ± kaldÄ±r ve veri setini sÄ±fÄ±rla
df = df.iloc[2:].reset_index(drop=True)

# Ä°lk 3 sÃ¼tun iÃ§in tek seviyeli baÅŸlÄ±klar oluÅŸtur
first_three_headers = ['YÄ±l', 'Ä°l Kodu', 'Ä°l AdÄ±']

# Ana baÅŸlÄ±klar ve alt baÅŸlÄ±klarÄ± tanÄ±mla
main_headers = [
    'Genel toplam', 'Okuma yazma bilmeyen', 'Okuma yazma bilen fakat bir okul bitirmeyen',
    'Ä°lkokul', 'Ä°lkÃ¶ÄŸretim', 'Ortaokul ve dengi meslek', 'Lise ve dengi meslek',
    'YÃ¼ksekokul veya fakÃ¼lte', 'YÃ¼ksek lisans', 'Doktora', 'Bilinmeyen'
]
sub_headers = ['Toplam', 'Erkek', 'KadÄ±n']

# Ã‡ok seviyeli baÅŸlÄ±klarÄ± oluÅŸtur
remaining_headers = [(main, sub) for main in main_headers for sub in sub_headers]

# TÃ¼m baÅŸlÄ±klarÄ± birleÅŸtir
final_headers = first_three_headers + remaining_headers[:df.shape[1] - len(first_three_headers)]

df.columns = pd.MultiIndex.from_tuples(
    [(header, '') if isinstance(header, str) else header for header in final_headers]
)

# Veri setini bir dosyaya kaydet
import pyreadr

# Veri Ã§erÃ§evesini Rdata olarak kaydet
pyreadr.write_rds('data/education_data.RData', df)
```

```{python}
# Veri setini bir dosyaya kaydet
import pyreadr

# Veri Ã§erÃ§evesini Rdata olarak kaydet
pyreadr.write_rds('education_data.RData', df)
```
# R'de kullanÄ±lmak Ã¼zere aÃ§Ä±klama

âœ… Veri seti baÅŸarÄ±yla kaydedildi: "data/education_data.RData"  
[Rdata](education_data.RData)

### Veri Seti BaÄŸlantÄ±sÄ±

Veri setine [buradan ulaÅŸabilirsiniz](education_data.RData).


**Description:**  
- The dataset's column structure is inspected.  
- The first few rows are displayed to validate adjustments.

---

# âœ… Summary and Results

After the preprocessing steps:

1. The dataset was successfully loaded.  
2. Yearly data partitioning was completed.  
3. Multi-level column headers were structured.  
4. Sample data from selected years was displayed for verification.  

---

# ğŸš€ Next Steps

- Missing value analysis and filling strategies  
- Data normalization and scaling  
- Visualization and analysis steps  

**This report provides a detailed overview of the data preprocessing steps and prepares the dataset for further analysis.** ğŸš€
